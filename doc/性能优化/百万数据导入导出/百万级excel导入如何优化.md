                                  高频面试题：百万级数据导入如何优化
一、常见场景
场景一：对于百万级别excel数据导入，如果优化？


二、痛点
1）数据量超过百万级别，采用主流的poi框架处理，会不会遇到OOM，处理速度会不会很慢？
2）一次性从db中读取百万级别数据，能否查出来数据或者查询很慢？
3）百万数据写入到一个sheet，写入效率低，打开超时慢？
4）百万数据单条插入sheet，频繁IO，性能会不会很差？
5）写入db一条条写非批量操作，数据库cpu紧张？如果批量写入，采用mybatis批量写入性能有瓶颈吗, 改为spring jdbc

二、解决方案
1）场景一和场景三解决方案：多线程+批量保存数据库
2）场景二解决方案：异步处理+批量保存数据到数据库

三、异步处理（这里简单聊下，后面有时间再详细讲解）
1、发送数据到消息队列（比较推荐，基本不丢失，实现稍微麻烦）

三、批量处理数据的几种方案对比


三、代码讲解及演示
......
