                                  高频面试题：性能优化之批量处理数据
一、常见场景
场景一：对于百万级别excel数据导入，如果优化？
场景二：高并发下写数据，如何快速响应，如何提升数据处理效率，尽可能减轻数据库的压力？
场景三、大批量消费消息队列消息的时候，如何提升数据处理效率，提高消费效率减少消息挤压？

二、解决方案
1）场景一和场景三解决方案：多线程+批量保存数据库
2）场景二解决方案：异步处理+批量保存数据到数据库

三、异步处理（这里简单聊下，后面有时间再详细讲解）
1、发送数据到消息队列（比较推荐，基本不丢失，实现稍微麻烦）
2、基于guava eventbus实现异步事件（实现简单，性能比较好，重启服务有丢失的风险）
3、基于线程池实现异步处理（实现简单，并发量不大，可以用，重启服务有丢失的风险）

三、批量处理数据的几种方案对比
1、通过for循环逐条导入100w数据，例如：
for(int i=0;i<1000000;i++){
   save(entity);
}
结果分析：：耗时900s
2022-07-10 17:35:10.592 INFO [dancechar-base-service,XNIO-1 task-1,4be7f2e99e65a1,1546061704931049472] c.l.d.base.biz.student.service.StudentService.saveStuListWithOne:66- 通过for完成百万数据插入！！！总耗时：900s
2022-07-10 17:35:11.052 INFO [dancechar-base-service,XNIO-1 task-1,4be7f2e99e65a1,1546065486100299776] c.l.dancechar.base.framework.ResponseLogAdvice.beforeBodyWrite:53- 当前请求返回结果：true
2022-07-10 17:35:11.113 INFO [dancechar-base-service,XNIO-1 task-1,4be7f2e99e65a1,1546065486356152320] c.l.d.framework.common.trace.TraceWebFilter.doFilter:52- 当前请求总耗时：901772ms

2、通过batch循环批量导入100w数据
saveBatch(entityList);
结果分析：耗时165s，性能相比1，提供5倍以上
2022-07-10 18:19:06.704 INFO [dancechar-base-service,XNIO-1 task-2,cad1de9712a53f,1546076540821831680] c.l.d.framework.common.trace.TraceWebFilter.printAccessLog:77- 开始当前请求-/sys/student/saveStuListWithBatch,方法-POST，body参数：{}
2022-07-10 18:19:06.719 INFO [dancechar-base-service,XNIO-1 task-2,cad1de9712a53f,1546076540842803200] c.l.d.b.biz.student.controller.StudentController.saveStuListWithBatch:51- 批量插入百万数据....
2022-07-10 18:21:52.258 INFO [dancechar-base-service,XNIO-1 task-2,cad1de9712a53f,1546076540842803200] c.l.d.base.biz.student.service.StudentService.saveStuListWithBatch:77- 批量插入百万数据！！！总耗时：165s
2022-07-10 18:21:52.664 INFO [dancechar-base-service,XNIO-1 task-2,cad1de9712a53f,1546077236912717824] c.l.dancechar.base.framework.ResponseLogAdvice.beforeBodyWrite:53- 当前请求返回结果：true
2022-07-10 18:21:52.678 INFO [dancechar-base-service,XNIO-1 task-2,cad1de9712a53f,1546077236975632384] c.l.d.framework.common.trace.TraceWebFilter.doFilter:52- 当前请求总耗时：165981ms

3、通过多线程batch循环批量导入100w数据
threadPoolTaskExecutor.execute(()->{
   saveBatch(entityList);
})
结果分析：耗时70s，性能相比2，提升2倍以上
2022-07-10 18:26:48.625 INFO [dancechar-base-service,XNIO-1 task-3,4bca21714d53a8,1546078181767774208] c.l.d.base.biz.student.service.StudentService.saveStuListWithThreadPoolBatch:112- 通过线程池批量插入百万数据！！！总耗时：70s
2022-07-10 18:26:48.636 INFO [dancechar-base-service,XNIO-1 task-3,4bca21714d53a8,1546078478309261312] c.l.dancechar.base.framework.ResponseLogAdvice.beforeBodyWrite:53- 当前请求返回结果：true
2022-07-10 18:26:48.644 INFO [dancechar-base-service,XNIO-1 task-3,4bca21714d53a8,1546078478342815744] c.l.d.framework.common.trace.TraceWebFilter.doFilter:52- 当前请求总耗时：70716ms


三、代码讲解及演示
......
